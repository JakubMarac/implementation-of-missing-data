# -*- coding: utf-8 -*-
"""projekt-adn-2025.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Qk7rlEhxsXgRgcqCl7Xp0zQLQ-dhFKoS
"""

import numpy as np
import pandas as pd

import missingno as msno
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.linear_model import LinearRegression
from xgboost import XGBRegressor
from pathlib import Path

from sklearn.experimental import enable_iterative_imputer  # noqa: F401
from sklearn.impute import IterativeImputer
from sklearn.ensemble import ExtraTreesRegressor

#wgranie danych
df_train = pd.read_csv('/content/drive/MyDrive/analiza-danych-niekompletnych/pzn-rent-test.csv')
df_test = pd.read_csv("/content/drive/MyDrive/analiza-danych-niekompletnych/pzn-rent-train.csv")
df_sample = pd.read_csv("/content/drive/MyDrive/analiza-danych-niekompletnych/pzn-sample-sub.csv")

RANDOM_STATE = 123
np.random.seed(RANDOM_STATE)

print("TRAIN shape:", df_train.shape)
print("TEST  shape:", df_test.shape)
print("SAMPLE shape:", df_sample.shape)
df_train.head()

# 2. Raport sentyneli -999
def report_sentinel_minus999(df, name):
    mask = (df == -999)
    cols_with_999 = mask.any()
    cols = cols_with_999[cols_with_999].index.tolist()
    print(f"=== {name}: kolumny z -999 ===")
    for col in cols:
        cnt = mask[col].sum()
        print(f"{col}: {cnt} wystąpień")
    if not cols:
        print("brak -999")
    print()

report_sentinel_minus999(df_train, "TRAIN")
report_sentinel_minus999(df_test,  "TEST")

# Podstawowa tabela braków (tylko info, nie używane dalej)
na_cnt = df_train.isna().sum().sort_values(ascending=False)
na_pct = (df_train.isna().mean() * 100).sort_values(ascending=False).round(2)
missing_summary = pd.DataFrame({"n_missing": na_cnt, "pct_missing": na_pct})
print("=== Missing summary (top 10) ===")
print(missing_summary.head(10))

# Wizualizacja braków (opcjonalnie)
msno.bar(df_train)
plt.show()
msno.matrix(df_train)
plt.show()
msno.heatmap(df_train)
plt.show()

# 3. Konwersja dat + sanity check na datach
date_cols = ["date_activ", "date_modif", "date_expire"]

for df in [df_train, df_test]:
    for col in date_cols:
        df[col] = pd.to_datetime(df[col], errors="coerce")

print("=== Typy dat po konwersji (TRAIN) ===")
print(df_train[date_cols].dtypes)

# kolejnosc dat (tylko informacyjnie)
cond_bad_order = (
    (df_train["date_activ"] > df_train["date_modif"]) |
    (df_train["date_modif"] > df_train["date_expire"])
)
df_bad_dates = df_train[cond_bad_order]
print("Złe kolejności dat (TRAIN):", df_bad_dates.shape[0])

# czas trwania ogłoszenia + anomalie
for df_name, df in [("train", df_train), ("test", df_test)]:
    duration = (df["date_expire"] - df["date_activ"]).dt.days

    df["listing_duration"] = duration
    df["duration_anomaly"] = (duration >= 365).astype(int)
    df.loc[duration >= 365, "listing_duration"] = np.nan

    print(f"=== {df_name} listing_duration ===")
    print(duration.describe())
    print("<=0 dni:", (duration <= 0).sum())
    print(">=365 dni:", (duration >= 365).sum())
    print()

# 4. Sanity check: price / flat_rent / flat_deposit
for df_name, df in [("train", df_train), ("test", df_test)]:
    print(f"=== {df_name} price & rent sanity ===")
    print("price <= 0:", (df["price"] <= 0).sum() if "price" in df.columns else "brak")
    print("flat_rent < 0:", (df["flat_rent"] < 0).sum())
    print("flat_deposit < 0:", (df["flat_deposit"] < 0).sum())
    print()

# anomalia: flat_rent > price (tylko train, bo price tylko tam)
mask_anomaly_rent = df_train["flat_rent"] > df_train["price"]
print("Liczba anomalii price/rent (flat_rent > price):", mask_anomaly_rent.sum())

df_train["rent_over_price_anomaly"] = mask_anomaly_rent.astype(int)
# USTAWIAMY TYLKO flat_rent NA NaN, price zostawiamy jako target
df_train.loc[mask_anomaly_rent, "flat_rent"] = np.nan
df_test["rent_over_price_anomaly"] = 0

# checkpoint
print("Po czyszczeniu rent vs price – ile NaN w flat_rent (TRAIN):",
      df_train["flat_rent"].isna().sum())



